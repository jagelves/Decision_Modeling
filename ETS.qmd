# ETS

In this section we will be introducing and applying the Error, Trend, Seasonality (ETS) model. This model provides a flexible approach for modeling and forecasting time series data by incorporating components for error, trend, and seasonality. The ETS model allows different combinations of these components to be included in the model based on the characteristics observed in the data.

## ETS Components

ETS models build on simple exponential smoothing (SES). The basic idea behind SES is to assign more weight to recent observations and gradually decrease the weights as the observations become older. The model emphasizes the most recent data points and gives less importance to older observations.

Mathematically, the simple exponential smoothing model can be defined as:

<center>Forecast Equation: $\hat{y}_{t+h}=l_t$</center>

<center>Smoothing Equation: $l_{t}=\alpha y_t + (1-\alpha)l_{t-1}$</center>

<br> where $\hat{y}_{t+h}$ is the forecast of period $t+h$, $l_{t}$ is smoothed value of the series at time $t$, $y_t$ is the value observed at the current time period $t$ and $\alpha$ is the smoothing parameter. Note that when $\alpha$ is equal to one, the forecast equation is equivalent to the Naive model, and when $\alpha$ is equal to zero, the smoothing equation is always $l_{t-1}$.

The SES model is useful when forecasting series that have no trend or seasonality. The SES model can easily be modified to account for trend and seasonality by adding additional components. For example, the Holt's linear trend method adds a component to account for a linear trend, the damped trend methods flatten the trend some time into the future, and the Holt-Winters model accounts for seasonality. The collection of models generated by adding different components are summarized as Error, Trend, and Seasonality (ETS) models. We apply the ETS model to the deliveries of the electric car company Tesla in the sections below.

## Tesla's Deliveries

Deliveries are a carefully watched number by Tesla shareholders and are the closest approximation of sales disclosed by the company. Additionally, Tesla's deliveries are closely followed due to their impact on financial markets, the EV industry, innovation and disruption, production efficiency, and the growth of the EV market. The numbers serve as a key performance indicator for Tesla's success and provide insights into the broader trends in the electric vehicle industry. Can we use the ETS model to forecast Tesla's deliveries?

## The Data {#sec-data}

The data can be found here [Tesla](https://ir.tesla.com/#quarterly-disclosure). Below is code that inputs the data as a tsibble in R.

```{r message=FALSE}
library(fpp3)

# Create tsibble
tesla<-tsibble(
  period=yearquarter(c("2016:Q1","2016:Q2","2016:Q3","2016:Q4",
                       "2017:Q1","2017:Q2","2017:Q3","2017:Q4",
                       "2018:Q1","2018:Q2","2018:Q3","2018:Q4",
                       "2019:Q1","2019:Q2","2019:Q3","2019:Q4",
                       "2020:Q1","2020:Q2","2020:Q3","2020:Q4",
                       "2021:Q1","2021:Q2","2021:Q3","2021:Q4",
                       "2022:Q1","2022:Q2","2022:Q3","2022:Q4",
                       "2023:Q1","2023:Q2")),
  deliveries=c(14.8,14.4,24.5,22.2,
               25,22,26.2,29.9,
               30,40.7,83.5,90.7,
               63,95.2,97,112,
               88.4,90.7,139.3,180.6,
               184.82,201.25,241.3,308.6,
               310.5,254.7,343.8,405.3,
               422.9,466.1),
  index=period     # This is the time variable
)
```

As you can see the tsibble is created with the `tsibble()` function included in the `fpp3` package. The `yearquarter()` function from the `lubridate` package is used to coerce the period data to a date. The time variable is then specified via the *index* parameter. The code below creates the plot of Tesla's deliveries using the `autoplot()` function.

```{r}
tesla %>% autoplot(.vars=deliveries) + theme_classic() +
  labs(title= "Tesla Car Deliveries", 
       subtitle = "Q1 2017 to Q2 2023") +
  xlab("Quarter") + ylab(" ")
```

The most striking aspect of Tesla's deliveries is the exponential trend. There also seems to be a seasonal component, with relatively higher production Q4 versus the other quarters. These characteristics will be adopted by the ETS model to forecast the series. Below we can see the STL decomposition that confirm these characteristics.

```{r}
tesla %>%
  model(STL(deliveries~trend() + season())) %>%
  components() %>% autoplot() + theme_classic()
```

## Models

To model the data and create the appropriate forecasts, we start by generating test and training sets from the available data.

```{r}
train_tesla<-filter_index(.data=tesla,"2016 Q1"~"2021 Q4")
test_tesla<-filter_index(.data=tesla,"2022 Q1"~"2023 Q2")
```

There is no fixed rule for determining the length of the train and test sets. In this example, it is important to allocate a sufficiently large portion of the data to the training set to capture the underlying seasonality and trend of Tesla's deliveries. The sets are easily created using the `filter_index()` function.

Five models will be estimated based on ETS. The first one is the Simple Exponential Smoothing model with additive errors (SES), the Holt model that includes an additive trend (HOLT), a dampened trend model (DAMPED), a damped model with seasonality (DAMPEDS), and finally an algorithmic function that attempts to select the best ETS model (see @FPP3, Chapter 8). Along with these five models two more models are set forth. The first one is a simple least squares model (LS) and the second one is a quadratic model with seasonality dummies (LSS).

Model selection will be done via cross validation. Recall, that the the `stretch_tsibble()` function reshapes the tsibble to accommodate for cross validation. The *.init* parameter sets the first eight observations to estimate our initial model and the *.step* argument increases the training set by four. Cross validation is done four periods ahead (a year) and accuracy measures are created by comparing forecasts to the test set.

Each component of the ETS model can be included as either multiplicative ($M$) or additive ($A$). The trend component can be assigned to be damped ($Ad$ or $Md$). If the component is to be omitted from the model, None ($N$) is specified. Below is the code to estimate the models and the results of the cross validation.

```{r results='hide', warning=FALSE, message=FALSE}
library(gt)
train_tesla %>% stretch_tsibble(.init = 8, .step=4) %>%
  model(
    SES=ETS(deliveries ~ error("A") + trend("N") + season("N")),
    HOLT=ETS(deliveries ~ error("A") + trend("A") + season("N")),
    DAMPED=ETS(deliveries ~ error("A") + trend("Ad") + season("N")),
    DAMPEDS=ETS(deliveries ~ error("A") + trend("Ad") + season("A")),
ALGO=ETS(deliveries),
LS = TSLM(deliveries ~ trend()+I(trend()^2)),
LSS = TSLM(deliveries ~ trend()+I(trend()^2)+season()))%>%
  forecast(h = 4) %>%
  accuracy(tesla) %>% select(-"ACF1") 
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
library(gt)
train_tesla %>% stretch_tsibble(.init = 8) %>%
  model(
    SES=ETS(deliveries ~ error("A") + trend("N") + season("N")),
    HOLT=ETS(deliveries ~ error("A") + trend("A") + season("N")),
    DAMPED=ETS(deliveries ~ error("A") + trend("Ad") + season("N")),
    DAMPEDS=ETS(deliveries ~ error("A") + trend("Ad") + season("A")),
ALGO=ETS(deliveries),
LS = TSLM(deliveries ~ trend()+I(trend()^2)),
LSS = TSLM(deliveries ~ trend()+I(trend()^2)+season()))%>%
  forecast(h = 4) %>%
  accuracy(tesla) %>% select(-"ACF1") %>% 
  gt() %>% cols_align("center") %>% 
  tab_header(title = 
               md("**Cross Validation Models**")) %>% tab_style(locations =                                                    cells_column_labels(columns = everything()),
  style = list(cell_borders(sides = "bottom", weight = px(3)),
    cell_text(weight = "bold"))) %>% 
  fmt_number(columns =c(ME,RMSE,MAE,MPE,MAPE,MASE,RMSSE),
             decimals = 3) %>%
  tab_style_body(
    style = cell_fill(color="lightgreen"),
    values = c("DAMPEDS","LSS"),
    targets ="row")
```

The accuracy measures reveal that the DAMPEDS and LSS models perform consistently well. Below, we will continue with the DAMPEDS and LSS models as the trend seems to be exponential and there seems to be evidence of seasonality. These model are estimated and saved into an object called *fit* below.

```{r}
fit <- tesla %>%
  model(
    DAMPEDS = ETS(deliveries ~ error("A") + trend("Ad") + season("A")),
    LSS = TSLM(deliveries ~ trend()+I(trend()^2)+season())
  )
```

If one is interested in retrieving the model coefficients, one can use the `tidy()` (or `coef()`) function. Below the function is used along with the *fit* object to retrieve the coefficients of the Least Squares model with seasonality:

```{r results='hide'}
tidy(fit) %>% filter(.model=="LSS") %>%
  select(-".model")
```

```{r echo=FALSE}

tidy(fit) %>% filter(.model=="LSS") %>%
  select(-".model") %>%
gt() %>%
  cols_align("center") %>% 
  tab_header(title = md("**LSS Model Coefficients**")) %>% 
  tab_style(locations = cells_column_labels(columns = everything()),
  style = list(cell_borders(sides = "bottom", weight = px(3)),
    cell_text(weight = "bold"))) %>%
  fmt_number(columns =c(estimate,std.error,statistic,p.value),
             decimals = 2) 
```

The output above, reveals that the seasonal dummy for Q4 is statistically significant at the $10$% confirming the seasonal pattern found in the decomposition (@sec-data). The plot below shows the fit of the models with the blue line representing the LSS model and the red line the DAMPEDS model.

```{r, warning=FALSE, message=FALSE}
tesla %>% autoplot(deliveries, lwd=1.2, alpha=0.5) + theme_classic() + 
  geom_line(aes(y = .fitted), col="blue",
            data = augment(fit)  %>% filter(`.model`=="LSS")) +
              geom_line(aes(y = .fitted), col="red",
            data = augment(fit) %>% filter(`.model`=="DAMPEDS")) + 
  labs(title= "Tesla Car Deliveries Fitted Values", 
       subtitle = "Q1 2017 to Q2 2023") +
  xlab("Quarter") + ylab(" ")
```

## Information Criterion

We can also attempt to select our models via the AIC, AICc, or BIC. The code below summarizes these measure for the models considered.

```{r warning=FALSE, results='hide'}
train_tesla %>%
  model(
    SES=ETS(deliveries ~ error("A") + trend("N") + season("N")),
    HOLT=ETS(deliveries ~ error("A") + trend("A") + season("N")),
    DAMPED=ETS(deliveries ~ error("A") + trend("Ad") + season("N")),
    DAMPEDS=ETS(deliveries ~ error("A") + trend("Ad") + season("A")),
ALGO=ETS(deliveries),
LS = TSLM(deliveries ~ trend()+I(trend()^2)),
LSS = TSLM(deliveries ~ trend()+I(trend()^2)+season())) %>% 
  report()  %>%
  select('.model',"AIC","AICc","BIC")
```

```{r warning=FALSE, echo=FALSE}
train_tesla %>%
  model(
    SES=ETS(deliveries ~ error("A") + trend("N") + season("N")),
    HOLT=ETS(deliveries ~ error("A") + trend("A") + season("N")),
    DAMPED=ETS(deliveries ~ error("A") + trend("Ad") + season("N")),
    DAMPEDS=ETS(deliveries ~ error("A") + trend("Ad") + season("A")),
ALGO=ETS(deliveries),
LS = TSLM(deliveries ~ trend()+I(trend()^2)),
LSS = TSLM(deliveries ~ trend()+I(trend()^2)+season())) %>% 
  report()  %>%
  select('.model',"AIC","AICc","BIC") %>% 
  gt() %>%
  cols_align("center") %>% 
  tab_header(title = md("**Model Fit Information Criterion**")) %>% 
  tab_style(locations = cells_column_labels(columns = everything()),
  style = list(cell_borders(sides = "bottom", weight = px(3)),
    cell_text(weight = "bold"))) %>% 
  tab_style_body(
    style = cell_fill(color="lightgreen"),
    values = "LSS",
    targets ="row") %>% 
  fmt_number(columns =c(AIC,AICc,BIC),
             decimals = 2) 
```

Here, once again the LSS model seems to perform the best as it provides the lowest values. Among the ETS models, the ALGO model now stands out. This should be of no surprise, as the ALGO model is designed to choose ETS components that minimize the AIC.

## Forecasts

Forecasts are created by using the *fit* object. We will forecast four quarters ahead using the `forecast()` function. The code below generates a table with the forecasts.

```{r message=FALSE, results='hide'}
library(gt)
fit %>%
  forecast(h = 4) %>% select(-".model") -> deliveries_fc
deliveries_fc
```

```{r message=FALSE, echo=FALSE}
library(gt)
fit %>%
  forecast(h = 4) %>% select(-".model") %>% 
  gt() %>%
  cols_align("center") %>% 
  tab_header(title = md("**Forecasts**")) %>%
  tab_style(
    locations = cells_column_labels(columns = everything()),
    style = list(
      cell_borders(sides = "bottom", weight = px(3)),
      cell_text(weight = "bold"))) %>% 
  fmt_number(columns =c(.mean),
             decimals = 2)
  
```

Forecasts for the four quarters are shown above, with the corresponding mean. In general, both models predict Tesla will continue its trend and increase its deliveries every quarter. According to the DAMPEDS model, Tesla is expected to deliver about $516,000$ cars on average. The plot below illustrates the forecasts for both models along with the $95$% prediction intervals. The increasing standard deviation for future periods reminds us that longer-period forecasts have even more uncertainty.

```{r}
fit %>%
  forecast(h = 4) %>%
  autoplot(tesla, level=95) +
  labs(x="Quarter", y="",
       title = "Tesla Car Deliveries Forecasts",
       subtitle = "Q1 2017 to Q2 2023") + theme_classic()
```

## Scenarios

On October 9, 2023, Tesla announced 435,059 deliveries for Q3, signaling strong performance. However, during the previous earnings call, Tesla had already cautioned investors about potential delivery impacts due to planned factory shutdowns and upgrades. These shutdowns are necessary to retool production lines for their upcoming vehicles, the Highland Model 3 and Cybertruck. Interestingly, a similar factory shutdown occurred in Q2 2022, giving us valuable historical data to make more precise predictions.

To factor in the effect of these shutdowns, we can introduce a dummy variable, where we assign a value of 1 during shutdown quarters and 0 otherwise. Here's the code:

```{r}
tesla<-mutate(tesla,
                Down=case_when(
                  period==yearquarter("2022 Q2") ~ 1,
                                       TRUE ~ 0))

```

The *Down* variable, captures the impact of factory shutdowns on deliveries. Now, we can incorporate this information into our Time Series Linear Model (TSLM) to estimate Tesla’s deliveries more accurately:

```{r}
fit <- tesla %>%
  model(
    LSS = TSLM(deliveries~trend()+
                 I(trend()^2)+season()+Down)
  )

```

Next, let's explore two possible scenarios: one where Tesla undergoes a factory shutdown and another where production continues uninterrupted. Using the `scenarios()` function, we can create a dataset for forecasting over the next four periods, simulating both situations:

```{r}
Down_Scenario <- scenarios(
  Factory_Down = new_data(tesla, 4) |>
    mutate(Down=rep(1,4)),
  Factory_Up = new_data(tesla, 4) |>
    mutate(Down=rep(0,4)),
  names_to = "Scenario")
```

Finally, we can visualize how each scenario affects Tesla’s future delivery forecasts. Whether Tesla experiences another factory shutdown or keeps production running smoothly, this analysis will help us better understand the potential outcomes.

```{r}
tesla %>%
  autoplot(deliveries) + 
  autolayer(forecast(fit,new_data=Down_Scenario),
            level=NULL)+ theme_classic() +
  labs(x="Quarter", y="",
       title = "Tesla Car Deliveries Forecasts",
       subtitle = "Scenario Forecast") + theme_classic()
```

The new forecast of 429,404 is now closer to the reported delivery number of 435,059 for Q3 2023 when compared to the analyst consensus estimate of 454,809. For the 4th quarter of 2023 the analyst consensus was 480,500, which is inline with the forecast of the LSS model (about 480,000). The 95% confidence interval of \[422,553, 537,182\] is retrieved using the `hilo()` function.

```{r}
fit %>% forecast(new_data=Down_Scenario) %>%
  hilo(95) %>% unpack_hilo("95%") %>%
  as_tibble() %>%
  select(Down,period,.mean,`95%_lower`,`95%_upper`) %>%
  gt() %>% fmt_number(columns=c(.mean,
                       `95%_lower`,`95%_upper`),
             decimals = 2)
  
```

## Readings

The main reading for ETS models comes from Chapter 8 of @FPP3. These readings provide a bit more detail on the mathematical background behind each model and a few more applications. For an overview of the moving averages, the Holt, and Winters' models review @PMS.

-   @FPP3 Chapter 8 (Exponential Smoothing).

-   @PMS Chapter 13.5 (Overview of Time Series Models), 13.6 (Moving Average Models), 13.7 (Exponential Smoothing Models).

## Leasons Learned

In this module you have been introduced to ETS model. Particularly you have learned to:

-   Use the `model()` and `ETS()` functions to estimate the model.

-   Identify when ETS model is superior to other model by using the cross validation and information criterion.

-   Forecast time series with the ETS model.

## Exercises {#exercises6}

1.  Tesla is rapidly expanding its footprint in renewable energy and energy storage solutions, with innovations like the Powerwall, Megapack, and Solar Roof driving the company forward. Tesla's energy storage systems are gaining traction in both residential and large-scale utility markets, while its vision of Virtual Power Plants (VPPs) is revolutionizing how power is managed and distributed.

    Tesla is forecasting strong growth in energy deployment as they continue to scale their products and enter new markets. You have been asked to help forecast Tesla Energy’s deployment for Q4 2024, using historical quarterly data on energy storage and solar deployments from previous years.

    You can find data on Tesla’s quarterly energy deployment (in megawatt hours) here: <https://jagelves.github.io/Data/teslaE.csv>

    Forecast Tesla Energy's deployment for the next four quarters using an ETS model with all additive terms, a TSLM model with linear trend and seasonality, and a TSLM model with quadratic trend and seasonality. Evaluate model performance using the information criterion. Finally, provide your forecast for the upcoming quarters with a graph. What is your expectation for next quarter? Does energy deployment go up or down relative to last quarter? What about when you compare to the same quarter last year?

<details>

<summary>Suggested Answer</summary>

We can use the code below to develop the models:

```{r message=FALSE}
library(tidyverse)
library(fpp3)
library(ggthemes)
rm(list=ls())
storage<-read_csv("http://jagelves.github.io/Data/teslaE.csv")

storage %>%
  mutate(Date=yearquarter(Date)) %>%
  as_tsibble(index=Date) -> storage_ts

storage_ts %>%
  model(LM=TSLM(EnergyStorage~trend()+season()),
        LM2=TSLM(EnergyStorage~trend()+I(trend()^2)+season()),
        ETS=ETS(EnergyStorage~error("A") + trend("A") + season("A"))) ->fit
```

To obtain the information criterion we can use the `glance()` function:

```{r}
fit %>% glance() %>% select(.model,AIC:BIC)
```

Forecasts are obtained with the `forecast()` function setting *h=4*.

```{r}
fit %>% forecast(h=4) %>%
  hilo(95)
```

Finally, the graph is obtained using the `autoplot()` and `autolayer()` functions:

```{r}
fit %>% forecast(h=4) %>% autoplot(level=NULL)+
  autolayer(storage_ts,EnergyStorage) + theme_clean()
```

Forecast suggest that energy deployment will go down relative to last quarter. However, if we compare the same quarter a year ago, energy deployment is expected to increase.

</details>

2.  Ice Cream Heaven is a small ice cream shop that has recently purchased a new ice cream-making machine to expand its production and meet increased demand during the summer months. The machine was installed in July 2023, and while it has helped boost production, it has also increased the shop's energy consumption.

    The owners of Ice Cream Heaven want to estimate how much more they are paying in energy bills due to this new machine. They have historical monthly energy consumption data before and after the machine was installed and want to forecast what their energy consumption would have been without the machine to compare it with the actual values. Use the data found here: <http://jagelves.github.io/Data/ElectricityBill.csv> and an ETS model with all additive components to provide your estimate.

<details>

<summary>Suggested Answer</summary>

The code below provides an estimate by forecasting the months of August 2023 onward with an ETS model with additive terms.

```{r message=FALSE}
library(tidyverse)
library(fpp3)
rm(list=ls())
Elec<-read_csv("http://jagelves.github.io/Data/ElectricityBill.csv")

Elec %>% mutate(Date=yearmonth(paste(Year, Month, sep = "-"))) %>% 
  select(Date,`Bill Amount`) %>% 
  as_tsibble(index=Date)-> Elec_ts

pre<-Elec_ts %>% filter_index(.~"2023 Jul")

pre %>% model(ETS=ETS(`Bill Amount`~error("A") + trend("A") + season("A"))) -> fitp

fitp %>% forecast(h=12) %>% 
  as_tibble() %>% select(Date,.mean) -> NoMach

Elec_ts %>% filter_index("2023 Aug"~.) %>% 
  as_tibble()  -> Mach
  
sum(Mach$`Bill Amount`- NoMach$.mean)

```

Following this analysis, the ice cream shop has paid an additional 649 dollars. Below is a graph that visualizes the difference:

```{r}
library(ggthemes)
Elec_ts %>% autoplot(`Bill Amount`) + theme_clean() +
  geom_vline(xintercept=as.Date("2023-06-01"), lty=2, col="blue") +
  labs(x="", title="Electric Bill in Dollars",
       subtitle="Forecast in blue") +
  autolayer(forecast(fitp,h=12), level=NULL)

```

</details>

3.  Refer back to question 2, where your task is to estimate the extra cost in energy of a machine. Use the entire data set and forecast as scenario where the machine is kept and one where the machine is sold. Change the model to a TSLM with linear trend and seasonality. How much extra would the ice cream shop pay if they kept the machine?

<details>

<summary>Suggested Answer</summary>

Create a dummy variable that tags the dates when the new machine was in operation and fit the TSLM model:

```{r}
Elec_ts<-mutate(Elec_ts,
                Down=case_when(
                  Date>=yearmonth("2023 7") ~ 1,
                  TRUE ~ 0))

Elec_ts %>%
  model(
    LM2 = TSLM(`Bill Amount`~trend()+season()+Down)) -> fit2

```

Now we can create a new tsibble with data that assumes the new machine and no new machine with the `scenarios()` function.

```{r}
Mach <- scenarios(
  New_Mach = new_data(Elec_ts, 12) %>% 
    mutate(Down=rep(1,12)),
  Old_Mach = new_data(Elec_ts, 12) %>% 
    mutate(Down=rep(0,12)),
  names_to = "Scenario")
```

Lastly, we can use this new data to forecast with our model:

```{r}
forecast(fit2,new_data=Mach) ->est
as_tibble(est) %>% group_by(Down) %>% 
  summarise(Sum=sum(.mean)) %>% pull(Sum) %>% diff()
```

It will cost the ice cream shop an additional 535 dollars in energy consumption to keep the machine. Below is a graph of the two scenarios:

```{r}
Elec_ts %>%
  autoplot(`Bill Amount`) + 
  autolayer(forecast(fit2,new_data=Mach),
            level=NULL)+ theme_classic() +
  labs(x="Months", y="",
       title = "Energy Consumption",
       subtitle = "Scenario Forecast") + theme_clean()

```

</details>

4.  Delta Airlines relies heavily on maintaining high load factors (the percentage of seats filled on flights) to maximize profitability and optimize operational efficiency. Accurately forecasting load factors helps Delta plan routes, set prices, and allocate resources effectively.

    Delta has ask for you to forecast the load factor the next four periods using historical data and two different time series models: the ETS model (algorithmic) and the TSLM model (with seasonality and trend). By doing so, you will help Delta better anticipate future demand and optimize its flight operations.

    You can find the load factor data here: <https://jagelves.github.io/Data/AirlinesLoad.csv> Evaluate both models based on their RMSE on the test set (January 2022 to December 2023). Choose the model with the lowest RMSE as the best method for forecasting. Using the chosen model, forecast Delta’s load factor for the next four months (January 2024 to April 2024).

<details>

<summary>Suggested Answer</summary>

Here is the R code to complete the task. Start by loading the data and creating the tsibble.

```{r message=FALSE}
library(tidyverse)
library(fpp3)
library(ggthemes)
rm(list=ls())
Load<-read_csv("http://jagelves.github.io/Data/AirlinesLoad.csv")

Load %>% mutate(Date=yearmonth(paste(Year, Month, sep = "-"))) %>% 
  filter(Airline=="Delta") %>% 
  select(Date,LF_total) %>% as_tsibble(index=Date) -> Load_ts

```

Now we can create the train and test sets with the dates provided:

```{r}
Load_ts %>% filter_index("2022 Jan"~"2023 Dec") -> train
Load_ts %>% filter_index("Jan 2024"~.) -> test
```

Next, estimate both models and compare the accuracy of their predictions on the test set:

```{r}
train %>% 
  model(TSLM=TSLM(LF_total~trend()+season()),
        ETS=ETS(LF_total)) -> fit

fit %>% forecast(test) %>% 
  accuracy(test) %>% select(.model,RMSE)
```

It seems like the algorithmic ETS performs better. Finally, let's forecast the series using the algorithmic ETS model:

```{r}
Load_ts %>% 
  model(ETS=ETS(LF_total)) %>% 
  forecast(h=4)
```

Here is the graph:

```{r}
Load_ts %>% 
  model(ETS=ETS(LF_total)) %>% 
  forecast(h=4) %>% autoplot(level=95) +
  autolayer(train,LF_total) + autolayer(test,LF_total,lty=2) +
   theme_clean() + 
  labs(title="Delta Airlines Load Factors",
       x="",y="")
```

</details>
